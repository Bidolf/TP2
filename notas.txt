pg-xml
	postgres xml
	base de dados do tp1
		temos ficheiros xml
	cria uma tabela onde guarda as conversões de csv para xml
		template está em ./docker/images/db/xml/initial_schema.sql
	usar alterações feitas no tp1 para ter o soft-delete
	(se calhar vamos usar a mesma tabela que tinhamos)
	
pg-rel
	postgres relacional
	base de dados relacional
	guarda os dados dos sightings como uma base de dados normal
		tem tabelas que são entidades do dataset do TP1
	
	as coordenadas devem ser guardadas em colunas do tipo geometry
		a estrutura é armazenar um POINT com 2 dimensões
			latitude e longitude
	utilizar UUID em vez de id's sequenciais em cada entidade
		não guardar a primeira coluna do dataset que é os id's 

	exemplo:
	CREATE TABLE public.sightings
		id              uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
		location_id      uuid NOT NULL,
		created_on      TIMESTAMP NOT NULL DEFAULT NOW(),
		updated_on      TIMESTAMP NOT NULL DEFAULT NOW()
		
	CREATE TABLE public.locations
		id				uuid PRIMARY KEY DEFAULT uuid_generate_v4(),
		coords			GEOMETRY,
		created_on      TIMESTAMP NOT NULL DEFAULT NOW(),
		updated_on      TIMESTAMP NOT NULL DEFAULT NOW()
	
	dados no geometry:
		CREATE TABLE geometries (name varchar, geom geometry);

		INSERT INTO geometries VALUES
		  ('Point', 'POINT(0 0)'),
		  ('Linestring', 'LINESTRING(0 0, 1 1, 2 1, 2 2)'),
		  ('Polygon', 'POLYGON((0 0, 1 0, 1 1, 0 1, 0 0))'),
		  ('PolygonWithHole', 'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0),(1 1, 1 2, 2 2, 2 1, 1 1))'),
		  ('Collection', 'GEOMETRYCOLLECTION(POINT(2 0),POLYGON((0 0, 1 0, 1 1, 0 1, 0 0)))');
	no nosso caso, vamos usar o point
	ex:	
		INSERT INTO lugares
		VALUES ('Viana', 'POINT(42.9955556 -71.4552778)'),)
		
importer
	aplicação do tipo daemon
	vai estar a correr no fundo
	vai procurar novos ficheiros csv no volume csv
	quando encontra um, inicia a conversão e, depois a migração para a base de dados pg-xml
		cada csv produz vários ficheiross xml
		a variável de ambiente NUM_XML_PARTS indica o número de ficheiros XML que deverão ser gerados


watcher
	aplicação do tipo daemon
	vai estar a correr no fundo
	vai procurar novos ficheiros xml na base de dados pg-xml
	quando encontra um, gera mensagens para o serviço broker
	tipos de tarefas nas mensagens
		importar uma entidade. gerar uma tarefa por entidade
		atualizar dados geográficos por cada entidade com dados geográficos incompletos
			não dá para atualizar dados antes de importar a entidade

broker
	instancia do rabbitMQ
	gera mensagens com as tarefas do sistema
	distribui-as pelos serviços migrator ou gis-updater
	
migrator
	aplicação do tipo daemon
	vai estar a correr no fundo
	recebe tarefas de migração de entidades detetadas nos ficheiros xml
		recebe uma tarefa do broker
		usa a API api-entities
		migra dados para a base de dados pg-rel
	podem haver vários containers do tipo migrator a correr ao mesmo tempo
	
gis-updater / update-gis
	aplicação do tipo daemon
	vai estar a correr no fundo
	recebe tarefas de atualização de dadoss geograficos de entidades detetadas nos ficheiros xml
		recebe uma tarefa do broker
		usa a API api-entities
		migra dados para a base de dados pg-rel
	podem haver vários containers do tipo migrator a correr ao mesmo tempo

api-entities
	aplicação do tipo Web API
		em Nest.js e Prisma
	a API deve permitir realizar CRUD de todas as entidades
		create, read, update, delete
		
	##ver enunciado, tem muitos detalhes##
	
	Todas as operações deverão ser validadas através dos modelos e respeitar as restrições de integridade e relações 
		(ex: não deverá ser possível apagar um Ator que já esteja incluído em algum filme)
	O formato de retorno de todos os dados é JSON
	Pontos extra: este serviço utilizar migrações para a criação da base de dados
	 
api-gis
	API em Django
	para obter dados geográficos por região
	tem dois endpoints
		GET /api/tile
			devolve todas as entidades numa determinada área
		 PATCH /api/entity/{ID}
			atualiza entidade através do seu id unico
	exemplo:
		GET {HOSTNAME}/api/tile?neLat=39.50&neLng=76.4&swLat=39.3&swLng=76.6 [200]
	isto cria um retângulo
	endpoint deve devolver entidades na base de dados pg-rel que estejam dentro desse retângulo
	O formato de retorno dos dados é GeoJSON 
	Os documentos em Geo JSON deverão retornar todas as propriedades da tabela, na região “properties” do formato, além da parte geométrica.
	
	Dicas: poderá ser utilizada no SQL a função dos PostGIS denominada ST_MakeEnvelope para selecionar as entidades dentro da região
""
	SELECT jsonb_build_object(
		'type',			'Feature',
		'id',			id,
		'geometry',		ST_AsGeoJSON(geom)::jsonb,
		'properties',	to_jsonb( t.* ) - 'id' - 'geom'
		) AS json
	FROM (VALUES (1, 'one', 'POINT(1 1)'::geometry)) AS t(id, name, geom);
""

api-proc
	API en Django
	tem um endpoint por cada função criada no rpc-server
		este rpc-server é o que foi criado no tp1
	a API comunica diretamente com o rpc-server
		passa os parâmetros ao rpc-server
		e devolve o retorno do rpc-server

api-graphql
	não é obrigatorio, mas serve como ponto de melhoria
	as funções para consulta de dados desenvolvidas no TP1 devem ter uma implementação correspondente utilizando GraphQL
	os dados deverão ser obtidos da base de dados pg-rel em vez da pg-xml, 
		sendo por isso necessário refazer as queries em SQL em vez de XPath


frontend-ent
	Frontend simples que permite efetuar consultas à API api-entities
	já temos a estrutura base em React
	
frontend-gis
	Frontend simples que permite efetuar consultas à API api-gis
	Este frontend utiliza Leaflet.js
	já temos a estrutura base em React

frontend-proc
	Frontend simples que permite efetuar consultas à API api-proc e api-graphql
	Deverá ser criado, para cada função, um formulário simples que permite indicar os argumentos a utilizar
	A interface deverá chamar a função através da api-proc e api-graphql (se tivermos), indicando o resultado de ambas


rpc-server
	o servidor rpc feito durante o tp1
	
	
	
Volumes
	temos o volume csv e o xml onde só têm os ficheiros csv e xml
	
Ports
	1****
		bases de dados disponibilizadas fora do Docker
		10001: pg-xml
		10002: pg-rel
		
	2****
		APIs acessíveis no exterior. De modo a simplificar o trabalho, não será utilizada autenticação para aceder a estes serviços.
		20001: api-entities
		20002: api-gis
		20003: api-graphql
		20004: api-proc
	3****
		interfaces web disponíveis que permitem aceder aos dados através das APIs
		30001: frontend-ent
		30002: frontend-gis
		30003: frontend-proc
		
	ligações
		30001:20001	frontend-ent:	api-entities
		30002:20002	frontend-gis:	api-gis
		30003:20003	frontend-proc:	api-proc
		30003:20004	frontend-proc:	api-proc






	